{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnNQYPduV7GdBsMXx0xvh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aKhalid1476/cnn_exoplanet_detector/blob/main/run_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHMOwRVfS9KY",
        "outputId": "c9b15126-1582-4540-a8cb-198abd0d2702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exoTrain.csv        100%[===================>] 250.08M   120MB/s    in 2.1s    \n",
            "exoTest.csv         100%[===================>]  27.57M  59.7MB/s    in 0.5s    \n"
          ]
        }
      ],
      "source": [
        "#setup libraries and environment {\"display-mode\":\"form\", \"form-width\":\"25%\"}\n",
        "import os\n",
        "import sys\n",
        "\n",
        "class HiddenPrints:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "\n",
        "with HiddenPrints():\n",
        "\n",
        "    # Installing Streamlit & pyngrok\n",
        "    !pip -q install streamlit\n",
        "    !pip -q install pyngrok\n",
        "    from pyngrok import ngrok\n",
        "    import streamlit as st\n",
        "    !wget \"https://raw.githubusercontent.com/NolanChai/model_repo/main/income.csv\"\n",
        "\n",
        "def launch_website():\n",
        "  try:\n",
        "    if ngrok.get_tunnels():\n",
        "      ngrok.kill()\n",
        "    tunnel = ngrok.connect()\n",
        "\n",
        "    print(\"Click this link to try your web app:\")\n",
        "    print(tunnel.public_url)\n",
        "\n",
        "    !streamlit run --server.port 80 app.py >/dev/null # Connect to the URL through Port 80 (>/dev/null hides outputs)\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    ngrok.kill()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Planet%20Hunters/exoTrain.csv'\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Planet%20Hunters/exoTest.csv'\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import  metrics\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score,ConfusionMatrixDisplay,precision_score,recall_score,f1_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, normalize\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv1D, Conv2D, MaxPooling2D, BatchNormalization, MaxPooling1D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "df_train = pd.read_csv('exoTrain.csv')\n",
        "df_train['LABEL'] = df_train['LABEL'] -1\n",
        "df_test = pd.read_csv('exoTest.csv')\n",
        "df_test['LABEL'] = df_test['LABEL'] - 1\n",
        "\n",
        "def plot_graphs(history, best):\n",
        "\n",
        "  plt.figure(figsize=[10,4])\n",
        "  # summarize history for accuracy\n",
        "  plt.subplot(121)\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy across training\\n best accuracy of %.02f'%best[1])\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "  # summarize history for loss\n",
        "  plt.subplot(122)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss across training\\n best loss of %.02f'%best[0])\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def analyze_results(model, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Helper function to help interpret and model performance.\n",
        "\n",
        "    Args:\n",
        "    model: estimator instance\n",
        "    X_train: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "    Input values for model training.\n",
        "    y_train : array-like of shape (n_samples,)\n",
        "    Target values for model training.\n",
        "    X_test: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "    Input values for model testing.\n",
        "    y_test : array-like of shape (n_samples,)\n",
        "    Target values for model testing.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    print(\"-------------------------------------------\")\n",
        "    print(\"Model Results\")\n",
        "    print(\"\")\n",
        "    print(\"Training:\")\n",
        "    if type(model) == keras.src.engine.sequential.Sequential:\n",
        "      train_predictions = model.predict(X_train)\n",
        "      train_predictions = (train_predictions > 0.5)\n",
        "      cm = confusion_matrix(y_train, train_predictions)\n",
        "      labels = [0, 1]\n",
        "      df_cm = pd.DataFrame(cm,index = labels,columns = labels)\n",
        "      fig = plt.figure()\n",
        "      res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "      #plt.yticks([1.25, 3.75], labels,va='center')\n",
        "      plt.title('Confusion Matrix - Test Data')\n",
        "      plt.ylabel('True label')\n",
        "      plt.xlabel('Predicted label')\n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.close()\n",
        "      ConfusionMatrixDisplay.from_estimator(model,X_train,y_train)\n",
        "      plt.show()\n",
        "\n",
        "    print(\"Testing:\")\n",
        "    if type(model) == keras.src.engine.sequential.Sequential:\n",
        "      test_predictions = model.predict(X_test)\n",
        "      test_predictions = (test_predictions > 0.5)\n",
        "      cm = confusion_matrix(y_test, test_predictions)\n",
        "      labels = [0, 1]\n",
        "      df_cm = pd.DataFrame(cm,index = labels,columns = labels)\n",
        "      fig = plt.figure()\n",
        "      res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "      #plt.yticks([1.25, 3.75], labels,va='center')\n",
        "      plt.title('Confusion Matrix - Test Data')\n",
        "      plt.ylabel('True label')\n",
        "      plt.xlabel('Predicted label')\n",
        "      plt.show()\n",
        "    else:\n",
        "      ConfusionMatrixDisplay.from_estimator(model,X_test,y_test)\n",
        "\n",
        "X_train = df_train.drop('LABEL', axis=1)\n",
        "y_train = df_train['LABEL']\n",
        "X_test = df_test.drop('LABEL', axis=1)\n",
        "y_test = df_test['LABEL']\n",
        "\n",
        "# Preprocess Data\n",
        "# Helper functions that we can run for the three augmentation functions that will be used, but not explroed in depth\n",
        "\n",
        "def smote(a,b):\n",
        "    model = SMOTE()\n",
        "    X,y = model.fit_resample(a, b)\n",
        "    return X,y\n",
        "\n",
        "def savgol(df1,df2):\n",
        "    x = savgol_filter(df1,21,4,deriv=0)\n",
        "    y = savgol_filter(df2,21,4,deriv=0)\n",
        "    return x,y\n",
        "\n",
        "def fourier(df1,df2):\n",
        "    X_train = np.abs(np.fft.fft(df1, axis=1))\n",
        "    X_test = np.abs(np.fft.fft(df2, axis=1))\n",
        "    return X_train,X_test\n",
        "\n",
        "def norm(df1,df2):\n",
        "    X_train = normalize(df1)\n",
        "    X_test = normalize(df2)\n",
        "    return X_train,X_test\n",
        "\n",
        "def robust(df1,df2):\n",
        "    scaler = RobustScaler()\n",
        "    X_train = scaler.fit_transform(df1)\n",
        "    X_test = scaler.transform(df2)\n",
        "    return X_train,X_test\n",
        "\n",
        "fourier_X_train, fourier_X_test = fourier(X_train, X_test)\n",
        "savgol_X_train, savgol_X_test = savgol(fourier_X_train, fourier_X_test)\n",
        "norm_X_train, norm_X_test = norm(savgol_X_train,savgol_X_test)\n",
        "robust_X_train, robust_X_test = robust(norm_X_train, norm_X_test)\n",
        "smote_X_train,smote_y_train = smote(robust_X_train, y_train)\n",
        "\n",
        "# Here we're adding the generated, augmented data onto the testing data\n",
        "# aug_X_train, new_X_test_data, aug_y_train, new_y_test_data = train_test_split(smote_X_train, smote_y_train, test_size=0.3)\n",
        "# aug_X_test = np.concatenate((robust_X_test, new_X_test_data), axis=0)\n",
        "# aug_y_test = np.concatenate((y_test, new_y_test_data), axis=0)\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Apply preprocessing steps to the dataframe.\"\"\"\n",
        "    X = df.drop('LABEL', axis=1).values\n",
        "    y = df['LABEL'].values\n",
        "    # Fourier transform\n",
        "    X = np.abs(np.fft.fft(X, axis=1))\n",
        "    # Savitzky-Golay filter\n",
        "    X = savgol_filter(X, 21, 4, deriv=0, axis=1)\n",
        "    # Normalize\n",
        "    X = normalize(X)\n",
        "    # Robust scaling\n",
        "    scaler = RobustScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    # SMOTE\n",
        "    smote = SMOTE()\n",
        "    X, y = smote.fit_resample(X, y)\n",
        "    # Expand dimensions for CNN input\n",
        "    X_cnn = np.expand_dims(X, axis=2)\n",
        "    return X, X_cnn, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.title('Hello World!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dYM7kxGUqbP",
        "outputId": "4573d7ad-a478-4738-897a-9f40c7102b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 32FUmgOExxNUtRGr4TRFHza5mqc_6rTFQxmvjn9rq8BLPHmrH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Oq3Yz-Tbcq",
        "outputId": "ae257d1d-85b5-4e1c-eab9-e5bf7d57c9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "launch_website()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps6kRZKSUuF1",
        "outputId": "6546a8bd-c535-4ee4-c626-61101917b6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click this link to try your web app:\n",
            "https://4d04aca2bb79.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-04T20:03:08+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-c996e9ca-ada3-4533-a75b-f69c6a9d3f91 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-09-04T20:03:08+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-80-c996e9ca-ada3-4533-a75b-f69c6a9d3f91 err=\"failed to start tunnel: session closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "cnn_path = '/content/gdrive/My Drive/cnn_exoplanets.zip'\n",
        "\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "model = tf.keras.models.load_model('cnn/cnn.keras')\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "U0eecEjCU240",
        "outputId": "bfb656af-426d-4652-e847-658ffa17e171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3193\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m48\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m799\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m799\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m3,201\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3193</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">799</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">799</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,201</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,949\u001b[0m (42.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,949</span> (42.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,649\u001b[0m (14.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,649</span> (14.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,300\u001b[0m (28.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,300</span> (28.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "X_train, X_train_cnn, y_train = preprocess_data(df_train)"
      ],
      "metadata": {
        "id": "re9VzoTeWThZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Load data\n",
        "df_train = pd.read_csv('exoTrain.csv')\n",
        "df_train['LABEL'] = df_train['LABEL'] - 1\n",
        "\n",
        "# Load the CNN model\n",
        "model = tf.keras.models.load_model('cnn/cnn.keras')\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Apply preprocessing steps to the dataframe.\"\"\"\n",
        "    X = df.drop('LABEL', axis=1).values\n",
        "    y = df['LABEL'].values\n",
        "    # Fourier transform\n",
        "    X = np.abs(np.fft.fft(X, axis=1))\n",
        "    # Savitzky-Golay filter\n",
        "    X = savgol_filter(X, 21, 4, deriv=0, axis=1)\n",
        "    # Normalize\n",
        "    X = normalize(X)\n",
        "    # Robust scaling\n",
        "    scaler = RobustScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    # SMOTE\n",
        "    smote = SMOTE()\n",
        "    X, y = smote.fit_resample(X, y)\n",
        "    # Expand dimensions for CNN input\n",
        "    X_cnn = np.expand_dims(X, axis=2)\n",
        "    return X, X_cnn, y\n",
        "\n",
        "X_train, X_train_cnn, y_train = preprocess_data(df_train)\n",
        "\n",
        "def predict(index):\n",
        "    \"\"\"Make a prediction using the Keras model.\"\"\"\n",
        "    tensor = X_train[index].reshape(1, -1, 1)\n",
        "    output = model.predict(tensor)\n",
        "    return output.flatten()[0]\n",
        "\n",
        "################################################################################\n",
        "##########=                   (Light Curves)                   =################\n",
        "################################################################################\n",
        "st.title('Exoplanet Light Curve Visualization with CNN Predictions')\n",
        "\n",
        "# Slider for selecting the index of the light curve\n",
        "index = st.slider(\"Select Index for Light Curve\", min_value=0, max_value=len(X_train)-1, value=12, step=1)\n",
        "\n",
        "# Display CNN prediction results\n",
        "prediction = predict(index)\n",
        "st.write(f\"Prediction (probability of being an exoplanet): {prediction:.4f}\")\n",
        "t_0 = st.slider(\"Start of Period (t_0)\", min_value=0, max_value=3197, value=430, step=1)\n",
        "period = st.slider(\"Length of Period\", min_value=0, max_value=3197, value=1184, step=1)\n",
        "\n",
        "# Create Plotly graph for the full light curve with a rectangle highlighting the period\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=X_train[index].flatten(), mode='lines', name='Light Curve'))\n",
        "fig.add_shape(type=\"rect\",\n",
        "              x0=t_0,\n",
        "              y0=min(X_train[index])-5,\n",
        "              x1=t_0+period,\n",
        "              y1=max(X_train[index])+5,\n",
        "              line=dict(color=\"Red\"),\n",
        "              fillcolor=\"LightPink\",\n",
        "              opacity=0.5)\n",
        "fig.update_layout(title=\"Box Covering One Period of Exoplanet Transit\",\n",
        "                  xaxis_title=\"Observation Point\",\n",
        "                  yaxis_title=\"Normalized Flux\",\n",
        "                  showlegend=True)\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# Create Plotly graph for just the selected period\n",
        "fig_period = go.Figure()\n",
        "fig_period.add_trace(go.Scatter(y=X_train[index, t_0: t_0+period].flatten(), mode='lines', name='Selected Period'))\n",
        "fig_period.update_layout(title=\"Plot of Just One Period\",\n",
        "                         xaxis_title=\"Observation Point\",\n",
        "                         yaxis_title=\"Normalized Flux\",\n",
        "                         showlegend=True)\n",
        "st.plotly_chart(fig_period, use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1UcVXceWg-K",
        "outputId": "4998bd0b-8e15-40a6-f50b-b27951560a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "launch_website()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF-rgI34Wnxb",
        "outputId": "c97d811e-b481-4881-b0e3-553c5ea91495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click this link to try your web app:\n",
            "https://108bccd31ac8.ngrok-free.app\n",
            "2025-09-04 20:11:02.004647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757016662.048998    4140 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757016662.061971    4140 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757016662.098649    4140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757016662.098733    4140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757016662.098739    4140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757016662.098743    4140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-04T20:11:13+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-c2508f0f-b49e-4b80-a77d-9f2ebbaab638 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-09-04T20:11:13+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-80-c2508f0f-b49e-4b80-a77d-9f2ebbaab638 err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-04 20:11:13.301335: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# Load data\n",
        "df_train = pd.read_csv('exoTrain.csv')\n",
        "df_train['LABEL'] = df_train['LABEL'] - 1\n",
        "\n",
        "# Load the CNN model\n",
        "cnn_model = tf.keras.models.load_model('cnn/cnn.keras')\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Apply preprocessing steps to the dataframe.\"\"\"\n",
        "    X = df.drop('LABEL', axis=1).values\n",
        "    y = df['LABEL'].values\n",
        "    # Fourier transform\n",
        "    X = np.abs(np.fft.fft(X, axis=1))\n",
        "    # Savitzky-Golay filter\n",
        "    X = savgol_filter(X, 21, 4, deriv=0, axis=1)\n",
        "    # Normalize\n",
        "    X = normalize(X)\n",
        "    # Robust scaling\n",
        "    scaler = RobustScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    # SMOTE\n",
        "    smote = SMOTE()\n",
        "    X, y = smote.fit_resample(X, y)\n",
        "    # Expand dimensions for CNN input\n",
        "    X_cnn = np.expand_dims(X, axis=2)\n",
        "    return X, X_cnn, y\n",
        "\n",
        "X_train, X_train_cnn, y_train = preprocess_data(df_train)\n",
        "\n",
        "def predict_cnn(index):\n",
        "    \"\"\"Make a prediction using the CNN model.\"\"\"\n",
        "    tensor = X_train_cnn[index].reshape(1, -1, 1)\n",
        "    output = cnn_model.predict(tensor)\n",
        "    return output.flatten()[0]\n",
        "\n",
        "st.title('Exoplanet Light Curve Visualization with CNN Predictions')\n",
        "\n",
        "# Slider for selecting the index of the light curve\n",
        "index = st.slider(\"Select Index for Light Curve\", min_value=0, max_value=len(X_train)-1, value=12, step=1)\n",
        "\n",
        "# Display CNN prediction results\n",
        "cnn_prediction = predict_cnn(index)\n",
        "st.write(f\"CNN Prediction (probability of being an exoplanet): {cnn_prediction:.4f}\")\n",
        "\n",
        "t_0 = st.slider(\"Start of Period (t_0)\", min_value=0, max_value=3197, value=430, step=1)\n",
        "period = st.slider(\"Length of Period\", min_value=0, max_value=3197, value=1184, step=1)\n",
        "\n",
        "# Checkbox widgets for graph selection\n",
        "show_full_light_curve = st.checkbox(\"Show Full Light Curve\", value=True)\n",
        "show_selected_period = st.checkbox(\"Show Selected Period\", value=True)\n",
        "show_confusion_matrix = st.checkbox(\"Show Confusion Matrix\", value=True)\n",
        "\n",
        "# Plotly graph for full light curve with rectangle highlighting the period\n",
        "if show_full_light_curve:\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(y=X_train[index].flatten(), mode='lines', name='Light Curve'))\n",
        "    fig.add_shape(type=\"rect\",\n",
        "                  x0=t_0,\n",
        "                  y0=min(X_train[index])-5,\n",
        "                  x1=t_0+period,\n",
        "                  y1=max(X_train[index])+5,\n",
        "                  line=dict(color=\"Red\"),\n",
        "                  fillcolor=\"LightPink\",\n",
        "                  opacity=0.5)\n",
        "    fig.update_layout(title=\"Box Covering One Period of Exoplanet Transit\",\n",
        "                      xaxis_title=\"Observation Point\",\n",
        "                      yaxis_title=\"Normalized Flux\",\n",
        "                      showlegend=True)\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# Plotly graph for just the selected period\n",
        "if show_selected_period:\n",
        "    fig_period = go.Figure()\n",
        "    fig_period.add_trace(go.Scatter(y=X_train[index, t_0: t_0+period], mode='lines', name='Selected Period'))\n",
        "    fig_period.update_layout(title=\"Plot of Just One Period\",\n",
        "                             xaxis_title=\"Observation Point\",\n",
        "                             yaxis_title=\"Normalized Flux\",\n",
        "                             showlegend=True)\n",
        "    st.plotly_chart(fig_period, use_container_width=True)\n",
        "\n",
        "# Compute and plot confusion matrices\n",
        "cnn_pred_labels = (cnn_model.predict(X_train_cnn).flatten() > 0.5).astype(int)\n",
        "cm_cnn = confusion_matrix(y_train, cnn_pred_labels)\n",
        "\n",
        "# Confusion Matrix for CNN\n",
        "if show_confusion_matrix:\n",
        "    fig_cm_cnn = ff.create_annotated_heatmap(z=cm_cnn, x=['Pred 0', 'Pred 1'], y=['True 0', 'True 1'],\n",
        "                                             colorscale='Viridis', showscale=True)\n",
        "    fig_cm_cnn.update_layout(title='Confusion Matrix for CNN for Entire Dataset')\n",
        "    st.plotly_chart(fig_cm_cnn, use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tii39NNWuwX",
        "outputId": "6aa3606c-fdc2-462e-b5f5-835b56ca91cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "launch_website()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYrZZTCAXE2_",
        "outputId": "d1acc0d7-e147-49d8-e578-425e055e7d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click this link to try your web app:\n",
            "https://1421d2073687.ngrok-free.app\n",
            "2025-09-04 20:13:05.123682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757016785.172226    4669 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757016785.186406    4669 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757016785.231741    4669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757016785.231807    4669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757016785.231817    4669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757016785.231825    4669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-04 20:13:39.041580: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-04T20:16:07+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-e85d4939-e893-46ea-9843-aefc2c81f0ef acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    }
  ]
}